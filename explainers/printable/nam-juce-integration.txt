================================================================================
                NAM & JUCE INTEGRATION - TECHNICAL EXPLAINER
                         Harmonica Documentation
================================================================================

WHAT IS NAM?
------------

NAM (Neural Amp Modeler) is a machine learning-based technology that
captures the sound of real guitar amplifiers and effects. Instead of
traditional algorithms that approximate amp behavior, NAM uses neural
networks trained on actual hardware to reproduce its exact tonal character.

Harmonica integrates NAM to provide authentic amp tones that would
otherwise require expensive gear and careful mic placement.


================================================================================
                    HOW NAM WORKS (Conceptually)
================================================================================

TRAINING PROCESS (Done Beforehand)
----------------------------------
1. A guitarist plays test signals through a real amplifier
2. Both the input (dry guitar) and output (amped signal) are recorded
3. A neural network is trained to learn the relationship between
   input and output
4. The trained model is saved as a .nam file

RUNTIME PROCESS (In Harmonica)
------------------------------
1. Your guitar signal enters Harmonica
2. The signal is fed into the trained neural network
3. The network outputs what the real amp would have produced
4. This processed signal continues down the signal chain

The result is a captured amp tone that responds to your playing dynamics,
picks up on your attack, and behaves like the original hardware.


================================================================================
                      NAM ARCHITECTURE TYPES
================================================================================

NAM supports several neural network architectures. Harmonica force-links
all of them to avoid static initialization issues:

WAVENET
-------
  - Deep convolutional network with dilated convolutions
  - Excellent quality, captures complex nonlinearities
  - Higher CPU usage
  - Best for high-gain and complex amp behavior

LSTM (Long Short-Term Memory)
-----------------------------
  - Recurrent neural network
  - Good at capturing time-dependent behavior
  - Moderate CPU usage
  - Works well for amps with strong compression characteristics

CONVNET (Convolutional Network)
-------------------------------
  - Standard convolutional architecture
  - Lower CPU usage
  - Good balance of quality and efficiency
  - Suitable for cleaner amp tones


================================================================================
                  NAM IN HARMONICA'S CODEBASE
================================================================================

KEY FILES
---------
  - Source/DSP/NAMProcessor.h     Header with class definition
  - Source/DSP/NAMProcessor.cpp   Implementation

MAIN CLASS: NAMProcessor
------------------------

    class NAMProcessor {
        // Model loading
        bool loadModel(const juce::File& namFile);

        // Audio processing
        void process(juce::AudioBuffer<float>& buffer);

        // Initialization
        void prepare(double sampleRate, int maxBlockSize);
        void reset();

        // State queries
        bool isModelLoaded() const;
        double getExpectedSampleRate() const;
    };


================================================================================
                          MODEL LOADING
================================================================================

THE LOADING PROCESS
-------------------

    bool NAMProcessor::loadModel(const juce::File& namFile)
    {
        // 1. Get file path
        std::string modelPath = namFile.getFullPathName().toStdString();

        // 2. Use NAM's factory function to create model
        model = nam::get_dsp(modelPath);

        // 3. Validate the model loaded successfully
        if (model == nullptr) return false;

        // 4. Mark as loaded (atomic for thread safety)
        modelLoaded.store(true);

        return true;
    }

IMPORTANT: LOAD ON BACKGROUND THREAD
------------------------------------
Model loading involves file I/O and neural network initialization, which
can take 100ms or more. NEVER call loadModel() on the audio thread - it
will cause audio dropouts.

    // Correct: Load on background thread
    juce::Thread::launch([this, file]() {
        namProcessor.loadModel(file);
    });

    // Wrong: Blocks audio thread!
    namProcessor.loadModel(file);  // Don't do this in processBlock()!


================================================================================
                        AUDIO PROCESSING
================================================================================

THE PROCESSING LOOP
-------------------

    void NAMProcessor::process(juce::AudioBuffer<float>& buffer)
    {
        // 1. Safety check
        if (!modelLoaded.load()) return;

        // 2. Convert stereo to mono (sum and divide by 2)
        // NAM models are mono - they expect a single channel
        float* monoData = createMonoMix(buffer);

        // 3. Check for silence (optimization)
        if (isSilent(monoData, numSamples)) {
            // Skip processing during silence
            handleSilence();
            return;
        }

        // 4. Process through the neural network
        if (needsResampling) {
            processWithResampling(monoData, numSamples);
        } else {
            model->process(monoData, outputBuffer, numSamples);
        }

        // 5. Copy mono result back to both stereo channels
        copyMonoToStereo(buffer, outputBuffer);
    }

WHY MONO PROCESSING?
--------------------
NAM models are trained on mono signals (one microphone on one amp).
Processing stereo would:

1. Double CPU usage (processing twice)
2. Create phase issues (two instances of the same nonlinear model)
3. Waste resources for no benefit

The solution: Sum to mono, process once, copy to both channels.


================================================================================
                      SAMPLE RATE HANDLING
================================================================================

THE PROBLEM
-----------
NAM models are trained at a specific sample rate (typically 48kHz). If
your DAW runs at a different rate (44.1kHz, 96kHz, etc.), the model won't
produce correct results.

THE SOLUTION: RESAMPLING
------------------------

    void NAMProcessor::prepare(double sampleRate, int maxBlockSize)
    {
        // Get the sample rate the model expects
        double modelRate = model->getExpectedSampleRate();

        // Calculate ratio
        resampleRatio = sampleRate / modelRate;

        // If rates differ by more than 1%, we need to resample
        needsResampling = std::abs(resampleRatio - 1.0) > 0.01;

        if (needsResampling) {
            // Allocate resampling buffers
            // Use Lagrange interpolation for high quality
            setupResampler(sampleRate, modelRate);
        }
    }

RESAMPLING FLOW
---------------

    DAW Sample Rate (e.g., 44.1kHz)
               |
               v
        [Upsample to 48kHz]    <-- Lagrange interpolation
               |
               v
        [NAM Processing]       <-- Model runs at expected rate
               |
               v
        [Downsample to 44.1kHz] <-- Lagrange interpolation
               |
               v
            Output


================================================================================
                       SILENCE DETECTION
================================================================================

WHY DETECT SILENCE?
-------------------
Neural network processing is expensive. When there's no guitar signal
(between songs, during breaks), we can skip processing entirely.

THE ALGORITHM
-------------

    bool NAMProcessor::isSilent(const float* data, int numSamples)
    {
        // Calculate RMS level
        float rms = 0.0f;
        for (int i = 0; i < numSamples; i++) {
            rms += data[i] * data[i];
        }
        rms = std::sqrt(rms / numSamples);

        // Check against threshold (-80dB = 0.0001)
        return rms < 0.0001f;
    }

DEBOUNCING
----------
To prevent rapid on/off switching at the end of notes:

    // Don't instantly switch to silence mode
    if (isSilent(data, numSamples)) {
        silenceCounter++;
        if (silenceCounter > GRACE_PERIOD) {  // ~250ms
            // Now we're confident it's actual silence
            enterSilenceMode();
        }
    } else {
        silenceCounter = 0;
        exitSilenceMode();
    }


================================================================================
                        JUCE INTEGRATION
================================================================================

JUCE'S ROLE
-----------
JUCE (Jules' Utility Class Extensions) is the audio application framework
Harmonica is built on. It provides:

  - Audio I/O abstraction (works with any audio interface)
  - Buffer management
  - Plugin format support (VST3, AU, Standalone)
  - GUI framework

NAM WITHIN JUCE'S AUDIO MODEL
-----------------------------

    class HarmonicaProcessor : public juce::AudioProcessor {
        NAMProcessor namProcessor;

        void prepareToPlay(double sampleRate, int samplesPerBlock) override {
            // Called when audio settings change
            namProcessor.prepare(sampleRate, samplesPerBlock);
        }

        void processBlock(juce::AudioBuffer<float>& buffer,
                          juce::MidiBuffer& midi) override {
            // Called ~1000 times per second with audio data
            namProcessor.process(buffer);
        }
    };

THREAD MODEL
------------
JUCE uses multiple threads:

1. Audio Thread: Runs processBlock() in real-time. Must never block.
2. Message Thread: Handles GUI updates and user interaction.
3. Background Threads: For file I/O, model loading, etc.

NAM integrates with this model:
  - loadModel(): Called from background thread
  - process(): Called from audio thread (uses atomic modelLoaded flag)
  - Parameter changes: Use atomic variables or juce::SmoothedValue


================================================================================
                       AUDIOBUFFER BASICS
================================================================================

JUCE's AudioBuffer<float> is how audio data moves around:

    juce::AudioBuffer<float> buffer(2, 512);  // 2 channels, 512 samples

    // Get raw pointer for channel 0
    float* leftChannel = buffer.getWritePointer(0);

    // Get raw pointer for channel 1
    float* rightChannel = buffer.getWritePointer(1);

    // Get number of samples
    int numSamples = buffer.getNumSamples();

    // Get number of channels
    int numChannels = buffer.getNumChannels();

NAM works with raw float pointers internally:

    void NAMProcessor::process(juce::AudioBuffer<float>& buffer) {
        float* data = buffer.getWritePointer(0);
        int numSamples = buffer.getNumSamples();

        // NAM's C API expects float* and sample count
        model->process(data, output, numSamples);
    }


================================================================================
                  ERROR HANDLING AND VALIDATION
================================================================================

INPUT VALIDATION
----------------

    void NAMProcessor::process(juce::AudioBuffer<float>& buffer)
    {
        // Check for invalid values (NaN, Infinity)
        for (int i = 0; i < numSamples; i++) {
            if (!std::isfinite(data[i])) {
                data[i] = 0.0f;  // Replace with silence
            }
        }

        // Process...

        // Validate output too
        for (int i = 0; i < numSamples; i++) {
            if (!std::isfinite(output[i])) {
                output[i] = 0.0f;
            }
        }
    }

DENORMAL FLUSHING
-----------------

    // Very small values can cause CPU spikes
    if (std::abs(sample) < 1e-15f) {
        sample = 0.0f;
    }


================================================================================
                    PERFORMANCE CONSIDERATIONS
================================================================================

CPU USAGE
---------
NAM models are computationally intensive. Tips:

1. Choose appropriate architecture: ConvNet < LSTM < WaveNet in CPU cost
2. Use silence detection: Skip processing when no input
3. Avoid resampling if possible: Run DAW at model's native rate
4. Buffer size: Larger buffers = less overhead, more latency

LATENCY
-------
NAM itself adds minimal latency (one buffer's worth). The main latency
in Harmonica comes from the Multivoicer's pitch shifter (~100ms).

MEMORY USAGE
------------
Models typically use 10-50MB of RAM, depending on architecture.


================================================================================
                   COMMON ISSUES AND SOLUTIONS
================================================================================

"MODEL WON'T LOAD"
------------------
  - Check file path is valid
  - Ensure .nam file isn't corrupted
  - Check if model architecture is supported

"AUDIO DROPOUTS WHEN LOADING MODEL"
-----------------------------------
  - Load models on background thread, never audio thread
  - Pre-load models during initialization

"TONE SOUNDS WRONG"
-------------------
  - Check sample rate matches model's expected rate
  - Verify model is actually loaded (isModelLoaded())

"HIGH CPU USAGE"
----------------
  - Try smaller model architecture
  - Increase buffer size
  - Enable silence detection


================================================================================
                        CODE FLOW SUMMARY
================================================================================

    Guitar Signal
          |
          v
    [JUCE AudioProcessor::processBlock()]
          |
          v
    [NAMProcessor::process()]
          |
          +-- Model loaded? --No--> Pass through unchanged
          |         |
          |        Yes
          |         |
          |         v
          |   [Sum to Mono]
          |         |
          |         v
          |   [Silence Detection]
          |         |
          |    +----+----+
          |   Yes       No
          |    |         |
          |    |    [Resampling needed?]
          |    |         |
          |    |    +----+----+
          |    |   Yes       No
          |    |    |         |
          |    | [Upsample]   |
          |    |    |         |
          |    |    v         v
          |    |  [NAM Neural Network]
          |    |    |         |
          |    | [Downsample] |
          |    |    |         |
          |    |    +----+----+
          |    |         |
          |    |    [Copy to Stereo]
          |    |         |
          +----+---------+
                  |
                  v
          [Output to next stage]


================================================================================
                          FILE REFERENCES
================================================================================

  Component           File
  ---------           ----
  NAM Processor       Source/DSP/NAMProcessor.h, NAMProcessor.cpp
  Plugin Processor    Source/PluginProcessor.h, PluginProcessor.cpp
  NAM Library         extern/NAM/ (third-party)


================================================================================
                         FURTHER READING
================================================================================

  - JUCE Documentation: https://juce.com/learn/documentation
  - NAM Project: https://github.com/sdatkinson/neural-amp-modeler
  - Signalsmith Stretch: https://signalsmith-audio.co.uk/code/stretch/

================================================================================
